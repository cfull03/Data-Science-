{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1LV7izNa82D",
    "outputId": "2e8263df-e7c0-477f-cd2a-260b1bcf0ec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nDR5ILDmaF1I"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtxDmxngrhE0"
   },
   "source": [
    "### Make sure your runtime type is either GPU or TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGznYvxIIvjy",
    "outputId": "1bfe49ae-9032-47b6-c2e2-8c314b00a629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LO3K14JN3pG-"
   },
   "source": [
    "The list of class names in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aM0CAgNwUUX0"
   },
   "outputs": [],
   "source": [
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "0T8CNxqxbBTM",
    "outputId": "f83771d2-5aec-44f5-af19-c0e357f48a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32]) torch.Size([128])\n",
      "truck\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "print(images.size(), labels.size())\n",
    "\n",
    "i = 12\n",
    "imshow(images[i].permute([1, 2, 0]).numpy()/2 + .5)\n",
    "axis('off')\n",
    "print(classes[labels[i].item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQO9KblUpw0L"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQdxxgWClBns"
   },
   "source": [
    "## Task 1\n",
    "Build a neural network with two *Linear* layers and an output layer. The first Linear layer should have 512 neurons and the second 128 neurons. Both layers should use *relu* activation function. After each of these *Linear* layers, you should have a *dropout* layer (torch.nn.Dropout) with dropout probability 0.2. The output layer\n",
    "should be a *Linear* layer.\n",
    "\n",
    "Use torch.nn.CrossEntropyLoss to compute the loss value of the model output. Use *adam* optimizer to update the model parameters when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwrN_8WJXbR_"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "model1 = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3 * 32 * 32,512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(128, len(classes))\n",
    ").to(device)\n",
    "\n",
    "CEL_loss = nn.CrossEntropyLoss()\n",
    "optimizer = opt.Adam(model1.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrboiPkOmko8"
   },
   "source": [
    "## Task 2\n",
    "Train the model for 50 epochs. Evaluate the model on the testing data. Print out the model accuracy on test data after the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUyvcurvU2l1"
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    model1.train()\n",
    "    for i, (X,y) in enumerate(trainloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model1(X)\n",
    "        loss = CEL_loss(pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{i + 1}/{len(trainloader)}], Loss: {running_loss / 100:.4f}')\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    model1.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in testloader:\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "            outputs = model1(X_test)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_test.size(0)\n",
    "            correct += (predicted == y_test).sum().item()\n",
    "            \n",
    "    print(f'Accuracy on test data after epoch {epoch + 1}: {(100 * correct / total):.2f}%')\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNYU1ulpnyyU"
   },
   "source": [
    "## Task 3\n",
    "Implement a function *recognize*. It takes an image (shape = 3, 32, 32) as an input and use the \"model\" you trained above to make a prediction of the image's class. Your function should return the predicted (string) class (use the classes list above to map numeric prediction to string label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8AExaK5OGu4"
   },
   "outputs": [],
   "source": [
    "def recognize(new_img):\n",
    "    model1.eval()\n",
    "    im_tensor = torch.tensor(new_img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model1(im_tensor)\n",
    "        \n",
    "    _, predicted = torch.max(output, 1)\n",
    "    return classes[predicted.item()]\n",
    "\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "new_img = images[0]\n",
    "\n",
    "pred = recognize(new_img.cpu())\n",
    "\n",
    "print('Neural network recognizes this image as:', pred)\n",
    "print('true image label:', classes[labels[0].item()])\n",
    "imshow(new_img.permute([1, 2, 0]).numpy()/2 + .5)\n",
    "axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8b3EktNs5Ek"
   },
   "source": [
    "### Task 4\n",
    "\n",
    "Implement a CNN with the following structure:\n",
    "- 4 Conv layers:  \n",
    "(3x3)x32, (3x3)x32, (3x3)x64, (3x3)x64\n",
    "\n",
    "- 2x2 Maxpool after 2nd and 4th conv.\n",
    "- Dropout after pooling\n",
    "- One FC layer and then a FC output layer\n",
    "\n",
    "Train the CNN model until training accuracy converges.\n",
    "(Compute accuracy on training data at the end of each epoch. Plot the accuracy values vs epochs to determine whether it converges.) Test the accuracy of the trained model on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yMnZlSnUwuh6"
   },
   "outputs": [],
   "source": [
    "cnn = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128 * 8 * 8, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = opt.Adam(cnn.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer):\n",
    "    epochs = 50\n",
    "    train_accuracy = [] \n",
    "    prev_accuracy = 0.0 \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "        train_accuracy.append(epoch_accuracy)\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(trainloader):.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "        if abs(epoch_accuracy - prev_accuracy) < 0.1:\n",
    "            print(\"Training accuracy converged.\")\n",
    "            break\n",
    "\n",
    "        prev_accuracy = epoch_accuracy\n",
    "\n",
    "    return train_accuracy\n",
    "\n",
    "def test(model, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = train(cnn, trainloader, criterion, optimizer)\n",
    "test_accuracy = test(cnn, testloader)\n",
    "\n",
    "plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
